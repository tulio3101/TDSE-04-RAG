{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff184b75",
   "metadata": {},
   "source": [
    "## Introduction to Creating RAGs (Retrieval-Augmented Generators) with OpenAI\n",
    "\n",
    "## 1. - Langchan LLM Chain Tutorial\n",
    "\n",
    "## 1.1 - Build a basic agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb7334a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0d30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='7773e436-2b62-4f36-833a-e391d28dd98f'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"sf\"}'}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c5e4a-a846-7d13-9b7a-ca262030c509-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': '2846b2f6-f579-4b94-a2de-1ea5e9c0ac4f', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 51, 'output_tokens': 15, 'total_tokens': 66, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in sf!\", name='get_weather', id='b4dd15e2-fa7e-4ad6-b472-715ab72293b3', tool_call_id='2846b2f6-f579-4b94-a2de-1ea5e9c0ac4f'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c5e4a-ab76-7650-af14-765b2f4bd976-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 88, 'output_tokens': 0, 'total_tokens': 88, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    "\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52290ac0",
   "metadata": {},
   "source": [
    "## 1.2 - Build a real-world agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9c62cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. \n",
    "If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb04b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76aa1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city. \"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema. \"\"\"\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e92863",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c5bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"google_genai:gemini-2.5-flash-lite\",\n",
    "    temperature=0.5,\n",
    "    timeout=10,\n",
    "    max_tokens=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e5237",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41bea203",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    punny_response: str\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016850b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96fa80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b3db1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "196b5b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response='I can\\'t give you a \"weather\" report, but I can tell you it\\'s always sunny in Florida!', weather_conditions='Sunny')\n",
      "ResponseFormat(punny_response='You\\'re welcome! I hope that was \"weather\" you were looking for!', weather_conditions=None)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.structured_output import ToolStrategy \n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_weather_for_location, get_user_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you\"}]},\n",
    "    config = config,\n",
    "    context = Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1ae7f",
   "metadata": {},
   "source": [
    "## 2. Build a RAG agent with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9932d131",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9667cfd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m pc = Pinecone(os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mPINECONE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m index = pc.Index(\u001b[43mindex_name\u001b[49m)\n\u001b[32m      8\u001b[39m vector_store = PineconeVectorStore(embedding=embeddings, index=index)\n",
      "\u001b[31mNameError\u001b[39m: name 'index_name' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "pc = Pinecone(os.environ.get(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vector_store = PineconeVectorStore(embedding=embeddings, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac133a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04af923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ba4 \n",
    "from langchain_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
